{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3e9471-df12-468d-8d88-bb11cdb3a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marconijiang/.pyenv/versions/3.13.1/envs/project-1/lib/python3.13/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def ollama_llm(history, question):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-r1:70b\",\n",
    "        # 將 prompt 進行截斷處理，避免過長\n",
    "        \"prompt\": f\"用繁體中文簡潔回答！\\n\\nQuestion: {question[:1000]}\",\n",
    "        \"stream\": False,\n",
    "        # 增加 max_tokens 參數限制輸出長度\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 1000  # 限制輸出 Token 數量\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            \n",
    "            # 截斷過長的回覆\n",
    "            generated_text = response_data.get(\"response\", \"\")[:2000]\n",
    "            generated_text = generated_text.replace('\\n', '\\n\\n')  # 增加換行\n",
    "            \n",
    "            # 計算 Token 資訊\n",
    "            eval_count = response_data.get(\"eval_count\", 0)\n",
    "            prompt_eval_count = response_data.get(\"prompt_eval_count\", 0)\n",
    "            total_duration = response_data.get(\"total_duration\", 0) / 1e9\n",
    "            \n",
    "            total_tokens = eval_count + prompt_eval_count\n",
    "            tokens_per_second = total_tokens / total_duration if total_duration > 0 else 0\n",
    "            elapsed_time = end_time - start_time\n",
    "            \n",
    "            # 更新對話歷史\n",
    "            # history.append((question, generated_text))\n",
    "            \n",
    "            history.append((\n",
    "                question, \n",
    "                f\"```\\n{generated_text}\\n```\"  # 使用代碼塊格式, 提供模型可以提供的更多訊息\n",
    "            ))\n",
    "            \n",
    "            \n",
    "            # 準備 Token 使用資訊\n",
    "            token_info = (\n",
    "                f\"執行時間：{elapsed_time:.2f} 秒\\n\"\n",
    "                f\"Token 使用：\\n\"\n",
    "                f\"- 輸入 Tokens: {prompt_eval_count}\\n\"\n",
    "                f\"- 輸出 Tokens: {eval_count}\\n\"\n",
    "                f\"- 總 Tokens: {total_tokens}\\n\"\n",
    "                f\"- Token 處理速度: {tokens_per_second:.2f} tokens/秒\"\n",
    "            )\n",
    "            \n",
    "            return history, token_info\n",
    "        \n",
    "        else:\n",
    "            error_msg = f\"API 請求失敗：{response.status_code} - {response.text}\"\n",
    "            history.append((question, error_msg))\n",
    "            return history, error_msg\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"系統異常：{str(e)}\"\n",
    "        history.append((question, error_msg))\n",
    "        return history, error_msg\n",
    "\n",
    "# Gradio 介面設定\n",
    "def create_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        history = gr.State([])\n",
    "        # 增加更多設定來處理長文本\n",
    "        chatbot = gr.Chatbot(\n",
    "            label=\"對話歷史\", \n",
    "            height=600,  # 增加高度\n",
    "            layout=\"bubble\",  # 使用氣泡佈局\n",
    "            bubble_full_width=False,  # 允許氣泡寬度自適應\n",
    "            render_markdown=True,  # 啟用 Markdown 渲染\n",
    "            show_copy_button=True,  # 增加複製按鈕\n",
    "            # 設定文字換行\n",
    "            line_breaks=True\n",
    "        )\n",
    "        \n",
    "        msg = gr.Textbox(label=\"輸入您的問題\")\n",
    "        submit_btn = gr.Button(\"發送\")\n",
    "        token_info = gr.Textbox(label=\"Token 使用資訊\", lines=5)\n",
    "        \n",
    "        submit_btn.click(\n",
    "            ollama_llm, \n",
    "            inputs=[history, msg], \n",
    "            outputs=[chatbot, token_info]\n",
    "        )\n",
    "        \n",
    "        msg.submit(\n",
    "            ollama_llm, \n",
    "            inputs=[history, msg], \n",
    "            outputs=[chatbot, token_info]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "\n",
    "# 啟動 Gradio 應用程式\n",
    "iface = create_interface()\n",
    "iface.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5540df-817f-42e0-b455-2618505c71b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
